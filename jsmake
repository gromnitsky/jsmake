#!/usr/bin/env node

class FirstTokenizer {
    constructor(input) {
	// TODO: join lines separated by '\'
	this.input = input.split("\n")

	this.tokens = [
	    { type: 'comment', re: '#.*$' },
	    { type: 'recipe',  re: '\t.*$' },
	    { type: 'identifier', re: '[^=:]+' },
	    { type: 'op',  re: '[=:]'},
	    { type: 'lvalue',  re: '.*$' },
	]
	this.line = 0
    }

    tokenize() {
	let r = []
	for (let line of this.input) {
	    this.line++
	    let column = 0
	    if (line.match(/^\s*$/)) continue

	    while (line.length) {
		for (let token of this.tokens) {
		    if (!line.length) break

		    let m = line.match(`^${token.re}`)
		    if (!m) continue
		    let skip = m.index + m[0].length
		    line = line.slice(0, m.index) + line.slice(skip)
		    r.push({type: token.type, val: m[0],
			    pos: `${this.line}:${column}:${column + skip - 1}`})
		    column += skip
		}
	    }
	}
	return r
    }
}

class Parser {
    constructor(tokens) {
	this.tokens = tokens
	this.vars = {}
	this.rules = []
    }

    parse() {
	let skip = -1
	for (let idx = 0; idx < this.tokens.length; ++idx) {
	    if (skip > idx) continue

	    let cur = this.tokens[idx]
	    let next = this.tokens[idx+1]

	    if (cur.type === 'identifier' && next && next.type === 'op') {
		skip = next.val === '=' ? this.variable(idx) : this.rule(idx)
	    } else if (cur.type === 'comment') {
		// TODO: annotate the last rule
	    } else {
		throw new Error(`${cur.pos}: unexpected ${cur.type}: ${cur.val}`)
	    }
	}
    }

    rule(idx) {
	let r = {
	    target: this.tokens[idx].val,
	}
	idx += 2
	if (this.tokens[idx] && this.tokens[idx].type === 'lvalue') {
	    r.deps = this.tokens[idx].val
	    idx++
	}

	let ri = idx
	let recipes = []
	while (this.tokens[ri] && this.tokens[ri].type === 'recipe') {
	    recipes.push(this.tokens[ri].val)
	    ri++
	}

	if (recipes.length) r.recipes = recipes
	this.rules.push(r)
	return ri
    }

    variable(idx) {
	let name = this.tokens[idx].val
	idx += 2
	if (this.tokens[idx] && this.tokens[idx].type !== 'lvalue') {
	    this.vars[name] = ''
	    return idx
	}
	this.vars[name] = this.tokens[idx] ? this.tokens[idx].val : ''
	return idx+1
    }
}

exports.FirstTokenizer = FirstTokenizer
exports.Parser = Parser

// Main
if (process.argv[1] === __filename) {
    let concat = require('concat-stream')

    let concat_stream = concat( input => {
	let tokens = new FirstTokenizer(input.toString()).tokenize()
	console.log(tokens)

	let parser = new Parser(tokens)
	parser.parse()
	console.log(parser.vars)
	console.log(parser.rules)
    })

    process.stdin.pipe(concat_stream)
}
